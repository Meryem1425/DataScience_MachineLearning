{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WELCOME!\n",
    "\n",
    "Welcome to ***Keras API Project***. This is the capstone project of ***Deep Learning Course***. This project is adapted from Jose Portilla's course and includes a subset created using the ***Lending Club Dataset***.\n",
    "\n",
    "As you know, ***Keras*** is a deep learning ***API*** written in Python, running on top of the machine learning platform ***TensorFlow***. \n",
    "\n",
    "In this project, you'll build a sequential model that your hands will be touching for the first time. You will discover how to create your first deep learning model in Python using Keras. \n",
    "\n",
    "Moreover, you will be working and exploring ***Google Colaboratory*** as an innovation and a facility instead of Jupyter Notebook.\n",
    "\n",
    "Before diving into the project, please take a look at the Determines and Tasks.\n",
    "\n",
    "- ***NOTE:*** *This tutorial assumes that you already know the basics of coding in Python and are familiar with the theory behind Deep Learning.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Determines\n",
    "\n",
    "\n",
    "LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n",
    "\n",
    "\n",
    "\n",
    "- **Feature information:**\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>LoanStatNew</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>loan_amnt</td>\n",
    "      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>term</td>\n",
    "      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>int_rate</td>\n",
    "      <td>Interest Rate on the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>installment</td>\n",
    "      <td>The monthly payment owed by the borrower if the loan originates.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>grade</td>\n",
    "      <td>LC assigned loan grade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>sub_grade</td>\n",
    "      <td>LC assigned loan subgrade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>emp_title</td>\n",
    "      <td>The job title supplied by the Borrower when applying for the loan.*</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>emp_length</td>\n",
    "      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>home_ownership</td>\n",
    "      <td>The home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>annual_inc</td>\n",
    "      <td>The self-reported annual income provided by the borrower during registration.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>verification_status</td>\n",
    "      <td>Indicates if income was verified by LC, not verified, or if the income source was verified</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>issue_d</td>\n",
    "      <td>The month which the loan was funded</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>loan_status</td>\n",
    "      <td>Current status of the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>purpose</td>\n",
    "      <td>A category provided by the borrower for the loan request.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>title</td>\n",
    "      <td>The loan title provided by the borrower</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>zip_code</td>\n",
    "      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>addr_state</td>\n",
    "      <td>The state provided by the borrower in the loan application</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>17</th>\n",
    "      <td>dti</td>\n",
    "      <td>A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>earliest_cr_line</td>\n",
    "      <td>The month the borrower's earliest reported credit line was opened</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>19</th>\n",
    "      <td>open_acc</td>\n",
    "      <td>The number of open credit lines in the borrower's credit file.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20</th>\n",
    "      <td>pub_rec</td>\n",
    "      <td>Number of derogatory public records</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>21</th>\n",
    "      <td>revol_bal</td>\n",
    "      <td>Total credit revolving balance</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>22</th>\n",
    "      <td>revol_util</td>\n",
    "      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>23</th>\n",
    "      <td>total_acc</td>\n",
    "      <td>The total number of credit lines currently in the borrower's credit file</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>initial_list_status</td>\n",
    "      <td>The initial listing status of the loan. Possible values are – W, F</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25</th>\n",
    "      <td>application_type</td>\n",
    "      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>26</th>\n",
    "      <td>mort_acc</td>\n",
    "      <td>Number of mortgage accounts.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>27</th>\n",
    "      <td>pub_rec_bankruptcies</td>\n",
    "      <td>Number of public record bankruptcies</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "- Additionally, provided feature information on the data as a CSV file for easy lookup.\n",
    "\n",
    "---\n",
    "\n",
    "When the bank hires a new potential customer, can you assess whether the customer can repay the loan?\n",
    "\n",
    "Regarding that, you'll create a model that can predict whether a borrower will be able to repay the loan, taking into account historical data on loans issued, along with information on whether the borrower is in default (charge-off).\n",
    "\n",
    "You currently have the data of a lending company. If you want to increase the success of your model, feature engineering is very effective for this. The prerequisite for feature engineering is to know the data well. In the exploratory data analysis process, try to learn the details of the data and plan your actions. Analyzng trends, patterns, and relatonshps in the Data. Examine the correlations of the features with the target variable.\n",
    "\n",
    "Moreover detect missing values and deal with them. Also remove unnecessary or duplicate features. Convert categorical string properties to dummy variables.\n",
    "\n",
    "At the end of this project; You will learn to develop a deep learning model with neural network architecture. Besides, you will learn hands-on about how you can evaluate the prediction success of the model you created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Tasks\n",
    "\n",
    "#### 1. Exploratory Data Analysis\n",
    "\n",
    "- Import Libraries, Load and Review the Data\n",
    "    \n",
    "#### 2. Data Cleaning\n",
    "\n",
    "- Outlier Detection\n",
    "- Handle with Missing Data\n",
    "\n",
    "#### 3. Feature Engineering\n",
    "\n",
    "\n",
    "#### 4. Data Pre-Processing\n",
    "\n",
    "- Train-Test Split\n",
    "- Scaling\n",
    "\n",
    " \n",
    "#### 5. Model Building\n",
    "\n",
    "- Import Libraries\n",
    "- Create a Sequential Model\n",
    "- Compile the Model\n",
    "- Fit the Model\n",
    "\n",
    "\n",
    "#### 6. Evaluating Model Performance\n",
    "- Plot out the validation loss vs. the training loss\n",
    "- Make Prediction\n",
    "- Create classification report and confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an understanding for which variables are important, view summary statistics, and visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries, Load and Review the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***i. Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ii. Load Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***iii. Review Data***\n",
    "\n",
    "Some exploring/reviewing tips:\n",
    "\n",
    "- Observe the target variable's class frequencies.\n",
    "- You may be particularly interested in features that are highly correlated with the target variable. You can detect multilinearity. You can use scatter plot.\n",
    "- Focus on numerical and categorical data seperately.\n",
    "- Detect Number of Unique values of each column.\n",
    "- Detect relationships and correlations between independent variables and target variable.\n",
    "- Detect relationships and correlations between independent variables. \n",
    "- Visualize class frequencies and distributions.\n",
    "- Create statistical summaries for continuous variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "It's a good practice to check if the data has any missing values or outliers. In real-world data, this is quite common and must be taken care of before any data pre-processing or model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection\n",
    "\n",
    "It doesn't matter for this project, but a short outlier detection is useful for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle with Missing Data\n",
    "\n",
    "There are many ways we could deal with this missing data. You could attempt to build a simple model to fill it in, such as a linear model. On the other hand you could just fill it in based on the mean of the other columns, or you could even bin the columns into categories and then set NaN as its own category.\n",
    "\n",
    "However, you may need to take a different approach for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you extract new features from existing variables?\n",
    "Is there a variable that does not carry any meaningful information or causes multilinearity?\n",
    "Are there variables such as timestamp that need to be converted to numeric or require a different action?\n",
    "Are there any categorical variables that need to be labeled?\n",
    "\n",
    "Below are tips for some variables. There are also different processes to do!\n",
    "\n",
    "- Create a column called ***zip_code*** that extracts the zip code from the ***address*** column. Make this zip_code column into dummy variables using pandas\n",
    "- ***issue_d*** variable would be data leakage, you wouldn't know beforehand whether or not a loan would be issued when using your model, so in theory you wouldn't have an issue_date, you can drop this feature.\n",
    "- ***earliest_cr_line*** variable appears to be a historical time stamp feature. Extract the year from this feature using a .apply function, then convert it to a numeric feature. Set this new data to a feature column called ***earliest_cr_year***.Then drop the ***earliest_cr_line*** feature.\n",
    "- In particular, don't forget to convert ***loan_status*** (target) to numeric form.\n",
    "\n",
    "***Note:*** *You will need to examine all the variables one by one and manipulate most of them. A lot of work to be done!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "You will keep some part of the data aside as a test set. The model will not use this set during training and it will be used only for checking the performance of the model is trained and un-trained states. This way, you can make sure that you are going in the right direction with your model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling \n",
    "\n",
    "We can make it easier for optimization algorithms to find minimas by normalizing the data before training a model.\n",
    "\n",
    "***Note:*** *Use a MinMaxScaler to normalize the feature data X_train and X_test. Recall you don't want data leakge from the test set so you only fit on the X_train data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building\n",
    "\n",
    "Implement a sequential model to assess whether a new client will be able to pay back the loan. You can discover **[how to create](https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5)** your first deep learning model in Python using **[Keras](https://keras.io/about/)**.\n",
    "\n",
    "Models in Keras are defined as a sequence of layers. The Sequential model API is a way of creating deep learning models where an instance of the Sequential class is created and model layers are created and added to it. In this section, we will look at defining a simple multilayer Perceptron. You can also create a Sequential model incrementally via the add() method.\n",
    "\n",
    "- Import libraries\n",
    "- Create a Sequential model and add layers one at a time until we are happy with your network architecture. ([build model architecture - hidden layers and hidden units](https://keras.io/guides/sequential_model/))\n",
    "- Compile the model by specifying an optimizer and a loss function and compute trainable parameters.\n",
    "- Fit the model\n",
    "- Evaluate model performance\n",
    "\n",
    "\n",
    "- ***Note***:  *Use .sample() to grab a sample of the 490k+ entries to save time on training. Highly recommended for lower RAM computers or if you are not using GPU.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Sequential Model\n",
    "\n",
    "[How to choose the number of hidden layers and nodes?](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "When compiling, you must specify some additional properties required when training the network. Remember training a network means finding the best set of weights to map inputs to outputs in your dataset.\n",
    "\n",
    "You must specify the loss function to use to evaluate a set of weights, the optimizer is used to search through different weights for the network and any optional metrics you would like to collect and report during training.\n",
    "\n",
    "Define the optimizer as the efficient stochastic gradient descent algorithm ***adam***. This is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems.\n",
    "\n",
    "In this case, you will use cross entropy as the loss argument. This loss is for a binary classification problems and is defined in Keras as ***binary_crossentropy***.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model\n",
    "\n",
    "\n",
    "Training occurs over epochs and each epoch is split into batches.\n",
    "\n",
    "The training process will run for a fixed number of iterations through the dataset called epochs, that we must specify using the epochs argument. We must also set the number of dataset rows that are considered before the model weights are updated within each epoch, called the batch size and set using the batch_size argument.\n",
    "\n",
    "Epochs and Batch_size configurations can be chosen experimentally by trial and error. We want to train the model enough so that it learns a good (or good enough) mapping of rows of input data to the output classification. The model will always have some error, but the amount of error will level out after some point for a given model configuration.\n",
    "\n",
    "- Fit the model to the training data for at least 25 epochs. Also add in the validation data for later plotting. Optional: add in a batch_size of 256\n",
    "- OPTIONAL: Save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Ideally, the loss is expected to go to zero and the accuracy to 1.0 (e.g. 100%). This is not possible for any but the most trivial machine learning problems. Instead, we will always have some error in our model. The goal is to choose a model configuration and training configuration that achieve the lowest loss and highest accuracy possible for a given dataset.\n",
    "\n",
    "- Plot out the validation loss vs. the training loss.\n",
    "- Create predictions from the X_test set and display a classification report and confusion matrix for the X_test set.\n",
    "- OPTIONAL: You can observe whether the model correctly predicts the loan_reload status for a randomly selected customer id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot out the validation loss vs. the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
